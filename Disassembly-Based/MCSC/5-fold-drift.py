# 使用hash_768和双线性插值缩放图像分类精度最高，为99%+，共10736个文件

import os
import os.path
import glob
import time
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils, plot_model


import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.cm as colormap

import numpy as np
import pandas as pd
np.random.seed(1)

from keras.preprocessing import image
from keras.preprocessing.image import img_to_array
from keras.applications.imagenet_utils import preprocess_input

from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.models import Sequential, Model, load_model
from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv2D, MaxPooling2D
from Cmodel import Cmodel

import keras
import csv
import cv2

os.environ['CUDA_VISIBLE_DEVICES'] = '1'


imagedir = "/home/mayixuan/MCSC-Simhash/drift/3gram_768_before"

epoch = 230
#save_parameters = '/home/mayixuan/MCSC-Simhash/drift/checkpoint/10-fold-MCSC.h5'
#Experiment_results = "/home/mayixuan/MCSC-Simhash/new/10-fold-result/"


def preprocess_input(x):
    x /= 255.
    x -= 0.5
    x *= 2.
    return x

cur_dir = os.getcwd()
os.chdir(imagedir)  # the parent folder with sub-folders

# Get number of samples per family
list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names
no_imgs = []  # No. of samples per family
for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png' 样本数向下取整
    no_imgs.append(len1)
    os.chdir('..')
num_samples = np.sum(no_imgs)  # total number of all samples

# Compute the labels
y = np.zeros(num_samples)
pos = 0
label = 0
for i in no_imgs:
    print ("Label:%2d\tFamily: %15s\tNumber of images: %d" % (label, list_fams[label], i))
    for j in range(i):
        y[pos] = label
        pos += 1
    label += 1
num_classes = label

# Compute the features
width, height, channels = (32, 32, 3)
X = np.zeros((num_samples, width, height, channels))
cnt = 0
list_paths = [] # List of image paths
print("Processing images ...")
start_3 = time.time()

All_imgs = []

for i in range(len(list_fams)):
    pro = 1
    for img_file in glob.glob(list_fams[i]+'/*.png'):

        All_imgs.append(img_file)  # 把所有图片名放入All_imgs数组中
        if pro > no_imgs[i]:
            break
        #print("[%d] Processing image: %s" % (cnt, img_file))
        list_paths.append(os.path.join(os.getcwd(), img_file))
#        img = image.load_img(img_file, target_size=(32, 32))
        img = cv2.imread(img_file)
        img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_CUBIC)
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        X[cnt] = x
        cnt += 1
        pro += 1
print("Images processed: %d" %(cnt))
end_3 = time.time()

os.chdir(cur_dir)


# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)
encoder = LabelEncoder()
encoder.fit(y)
y_encoded = encoder.transform(y)
Y = np_utils.to_categorical(y_encoded)




# Create stratified 10-fold subsets
kfold = 5  # no. of folds
skf = StratifiedKFold(kfold, shuffle=True, random_state=1)
skfind = [None] * kfold  # skfind[i][0] -> train indices, skfind[i][1] -> test indices   分层抽样
cnt = 0
for index in skf.split(X, y):
    skfind[cnt] = index
    cnt += 1


for i in range(kfold):
    train_indices = skfind[i][0]
    test_indices = skfind[i][1]
    X_train = X[train_indices]
    Y_train = Y[train_indices]
    X_test = X[test_indices]
    Y_test = Y[test_indices]
    y_test = y[test_indices]


    # Training top_model and saving min training loss weights
    num_epochs = epoch
    history = []
    checkpointer = ModelCheckpoint(
        filepath='/home/mayixuan/MCSC-Simhash/drift/checkpoint/fold-%d-%d-epoch.h5' % (i+1, epoch),
        monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='min')



    model = Cmodel()

    model.compile(optimizer=keras.optimizers.SGD(lr=0.005, momentum=0.1), loss='categorical_crossentropy', metrics=['accuracy'])


    start = time.time()
    h = model.fit(X_train, Y_train, validation_split=1/9, epochs=num_epochs,
                      batch_size=64, verbose=0, callbacks=[checkpointer])
    end = time.time()
    history.append(h)


    # 加载效果最好的模型，在上面做测试
    best_model = load_model('/home/mayixuan/MCSC-Simhash/drift/checkpoint/fold-%d-%d-epoch.h5' % (i+1, epoch))
    best_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.005, momentum=0.1),
                       metrics=['accuracy'])

    start_2 = time.time()
    y_prob = best_model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_prob, axis=1)
    end_2 = time.time()

    # 时间开销
    print()
    print()
    print('-----------------------------------------------------------------------')
    print('第 %d 次交叉验证' % (i+1))
    print('图片处理size用时：%.4f s ' % (end_3 - start_3))
    print("训练一个fold用时: %.4f s" % (end - start))
    print("预测 %d 个样本用时 : %.4f s" % (len(X_test), end_2 - start_2))

    # 一个fold的分类性能
    print(classification_report(y_test, y_pred, digits=4))