import os.path
import glob
import time
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import StratifiedKFold, train_test_split

from sklearn.metrics import confusion_matrix,accuracy_score,classification_report

import matplotlib
matplotlib.use('Agg')

import numpy as np
np.random.seed(1)

from keras.utils import np_utils
from keras.preprocessing import image
from keras.applications.inception_v3 import InceptionV3
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import Model, load_model
from keras.layers import Input, Dense, GlobalAveragePooling2D


os.environ['CUDA_VISIBLE_DEVICES'] = '0'

imagedir = "BIG-15"

epoch = 500
save_parameters = 'results/InceptionV3-transfer.h5'


def preprocess_input(x):
    x /= 255.
    x -= 0.5
    x *= 2.
    return x

cur_dir = os.getcwd()
os.chdir(imagedir)  # the parent folder with sub-folders

# Get number of samples per family
list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names
no_imgs = []  # No. of samples per family
for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    len1 = len(glob.glob('*.png'))  # 取百分之x，样本数向下取整
    no_imgs.append(len1)
    os.chdir('..')
num_samples = np.sum(no_imgs)  # total number of all samples

# Compute the labels
y = np.zeros(num_samples)
pos = 0
label = 0
for i in no_imgs:
    print ("Label:%2d\tFamily: %15s\tNumber of images: %d" % (label, list_fams[label], i))
    for j in range(i):
        y[pos] = label
        pos += 1
    label += 1
num_classes = label

# Compute the features
width, height,channels = (224,224,3)
X = np.zeros((num_samples, width, height, channels))
cnt = 0
list_paths = [] # List of image paths
print("Processing images ...")
for i in range(len(list_fams)):
    pro = 1
    for img_file in glob.glob(list_fams[i]+'/*.png'):
        if pro > no_imgs[i]:
            break
        #print("[%d] Processing image: %s" % (cnt, img_file))
        list_paths.append(os.path.join(os.getcwd(),img_file))
        img = image.load_img(img_file, target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        X[cnt] = x
        cnt += 1
        pro += 1
print("Images processed: %d" %(cnt))

os.chdir(cur_dir)

# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)
encoder = LabelEncoder()
encoder.fit(y)
y_encoded = encoder.transform(y)
Y = np_utils.to_categorical(y_encoded)


# Creating base_model (ResNet50 notop)
image_shape = (224, 224, 3)
base_model = InceptionV3(weights='imagenet', input_shape=image_shape, include_top=False)


filename = 'extracted-features/BIG15-inceptionv3features.npy'
if os.path.exists(filename):
    print("Loading Inceptionv3 extracted features from %s ..." %(filename))
    inceptionv3features = np.load(filename)
else:
    print("Extracting features from Inception-v3 layers ...")
    inceptionv3features = base_model.predict(X)
    print("Saving Inceptionv3 extracted features into %s ..." %(filename))
    np.save(filename, inceptionv3features)


# Create stratified k-fold subsets
kfold = 10  # no. of folds
skf = StratifiedKFold(kfold, shuffle=True,random_state=1)
skfind = [None] * kfold  # skfind[i][0] -> train indices, skfind[i][1] -> test indices
cnt = 0
for index in skf.split(X, y):
    skfind[cnt] = index
    cnt += 1

# Training top_model and saving min training loss weights
num_epochs = epoch
history = []
conf_mat = np.zeros((len(list_fams), len(list_fams)))  # Initializing the Confusion Matrix
early = EarlyStopping(monitor='val_loss', patience=15, mode='min')
checkpointer = ModelCheckpoint(filepath=save_parameters,
                               monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')
callbacks_list = [early, checkpointer]

all_time = 0

for i in range(1):
    train_indices = skfind[i][0]
    test_indices = skfind[i][1]
    X_train = inceptionv3features[train_indices]
    Y_train = Y[train_indices]
    X_test = inceptionv3features[test_indices]
    Y_test = Y[test_indices]
    y_test = y[test_indices]

    top_input = Input(shape=inceptionv3features.shape[1:])
    x = GlobalAveragePooling2D(name='avg_pool')(top_input)
    predict = Dense(num_classes, activation='softmax', name='predictions')(x)
    top_model = Model(inputs=top_input, outputs=predict)
    top_model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])


    start = time.time()
    h = top_model.fit(X_train, Y_train, validation_split=1/9, epochs=num_epochs,
                      batch_size=X_train.shape[0], verbose=2, callbacks=callbacks_list)
    end = time.time()
    history.append(h)

    # load the best model
    best_model = load_model(save_parameters)

    start_2 = time.time()
    y_prob = best_model.predict(X_test, verbose=1)  # Testing
    y_pred = np.argmax(y_prob, axis=1)
    end_2 = time.time()

    # Print process information
    print("[%d] Test acurracy: %.4f (%.4f s)" % (i, accuracy_score(y_test, y_pred), end - start))
    print()
    print()
    print('-----------------------------------------------------------------------')
    print('the %d fold' % (i + 1))
    print('train a fold using: %.4f s' % (end - start))
    per_fold_time = end - start
    all_time += per_fold_time
    print("predict %d test samples using: %.4f s" % (len(X_test), end_2 - start_2))
    print(classification_report(y_test, y_pred, digits=4))
    print('confusion matrix:')
    print()

    cm = confusion_matrix(y_test, y_pred)  # Compute confusion matrix for this fold
    print(cm)
    conf_mat = conf_mat + cm  # Compute global confusion matrix
    print(conf_mat)

# Computing the average accuracy
avg_acc = np.trace(conf_mat)/sum(no_imgs)
print("Average acurracy: %.4f" %(avg_acc))
print("All time: %.4f" % (all_time))