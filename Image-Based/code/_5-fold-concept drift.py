import os
import os.path
import glob
import time
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils, plot_model

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.cm as colormap

import numpy as np
import pandas as pd
np.random.seed(1)

from keras.applications.vgg16 import VGG16
from keras.preprocessing import image
from keras.preprocessing.image import img_to_array
from keras.applications.imagenet_utils import preprocess_input

from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.models import Sequential, Model, load_model
from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv2D, MaxPooling2D

import keras
import csv

os.environ['CUDA_VISIBLE_DEVICES'] = '2'


imagedir = "Big-Drift-Dataset-2/Before-7-family/"

epoch = 30
#save_parameters = '/home/mayixuan/mal-visual/checkpoint/Drift/5-fold-300epoch.h5'
#Experiment_results = " "



def preprocess_input(x):
    x /= 255.
    x -= 0.5
    x *= 2.
    return x

cur_dir = os.getcwd()
os.chdir(imagedir)  # the parent folder with sub-folders

# Get number of samples per family
list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names
no_imgs = []  # No. of samples per family
for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    len1 = len(glob.glob('*.png'))  # assuming the images are stored as 'png' 样本数向下取整
    no_imgs.append(len1)
    os.chdir('..')
num_samples = np.sum(no_imgs)  # total number of all samples

# Compute the labels
y = np.zeros(num_samples)
pos = 0
label = 0
for i in no_imgs:
    print ("Label:%2d\tFamily: %15s\tNumber of images: %d" % (label, list_fams[label], i))
    for j in range(i):
        y[pos] = label
        pos += 1
    label += 1
num_classes = label

# Compute the features
width, height,channels = (224, 224, 3)
X = np.zeros((num_samples, width, height, channels))
cnt = 0
list_paths = [] # List of image paths
print("Processing images ...")
start_3 = time.time()


for i in range(len(list_fams)):
    pro = 1
    for img_file in glob.glob(list_fams[i]+'/*.png'):


        #print("[%d] Processing image: %s" % (cnt, img_file))
        list_paths.append(os.path.join(os.getcwd(),img_file))
        img = image.load_img(img_file, target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        X[cnt] = x
        cnt += 1
        pro += 1
print("Images processed: %d" %(cnt))
end_3 = time.time()

os.chdir(cur_dir)


# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)
encoder = LabelEncoder()
encoder.fit(y)
y_encoded = encoder.transform(y)
Y = np_utils.to_categorical(y_encoded)




# Creating base_model (VGG16 notop)
image_shape = (224, 224, 3)
base_model = VGG16(weights='imagenet', input_shape=image_shape, include_top=False)



# Create stratified 5-fold subsets
kfold = 5  # no. of folds
skf = StratifiedKFold(kfold, shuffle=True, random_state=1)
skfind = [None] * kfold  # skfind[i][0] -> train indices, skfind[i][1] -> test indices   分层抽样
cnt = 0
for index in skf.split(X, y):
    skfind[cnt] = index
    cnt += 1

# Training top_model and saving min training loss weights
num_epochs = epoch

for i in range(kfold):
    train_indices = skfind[i][0]
    test_indices = skfind[i][1]
    X_train = X[train_indices]
    Y_train = Y[train_indices]
    X_test = X[test_indices]
    Y_test = Y[test_indices]
    y_test = y[test_indices]

    history = []
    checkpointer = ModelCheckpoint(
        filepath='/home/mayixuan/mal-visual/checkpoint/Drift/fold-%d-%depoch.h5' % (i+1, epoch),
        monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='min')


    x = base_model.output
    x = Flatten(name='flatten')(x)  # input_shape=(7,7,512)
    x = Dense(units=1024, activation='relu', name='FC-1', kernel_initializer='random_normal')(x)
    x = Dense(units=1024, activation='relu', name='FC-2', kernel_initializer='random_normal')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(num_classes, activation='softmax', name='predictions', kernel_initializer='random_normal')(x)

    vgg_model = Model(inputs=base_model.input, outputs=predictions)  # 网络链接


    # 冻结conv block5之前的所有卷积层权重，不包括输入层
    for layer in vgg_model.layers[1:15]:
        layer.trainable = False

    vgg_model.compile(optimizer=keras.optimizers.SGD(lr=5e-4, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])


    start = time.time()
    h = vgg_model.fit(X_train, Y_train, validation_split=1/9, epochs=num_epochs,
                      batch_size=32, verbose=1, callbacks=[checkpointer])
    end = time.time()
    history.append(h)



    # 加载效果最好的模型，在上面做测试
    best_model = load_model('/home/mayixuan/mal-visual/checkpoint/Drift/fold-%d-%depoch.h5' % (i+1, epoch))
    best_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=5e-4, momentum=0.9),
                       metrics=['accuracy'])



    start_2 = time.time()
    y_prob = best_model.predict(X_test, verbose=0)
    y_pred = np.argmax(y_prob, axis=1)
    end_2 = time.time()

    # 时间开销
    print()
    print()
    print('-----------------------------------------------------------------------')
    print('第 %d 次交叉验证' % (i+1))
    print('图片处理size用时：%.4f s ' % (end_3 - start_3))
    print("训练一个fold用时: %.4f s" % (end - start))
    print("预测 %d 个样本用时 : %.4f s" % (len(X_test), end_2 - start_2))

    # 一个fold的分类性能
    print(classification_report(y_test, y_pred, digits=4))
