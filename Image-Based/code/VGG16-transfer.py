import os.path
import glob
import time
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import confusion_matrix,accuracy_score,classification_report
from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils

import matplotlib
matplotlib.use('Agg')

import numpy as np
np.random.seed(1)

import keras

from keras.applications.vgg16 import VGG16
from keras.preprocessing import image


from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.models import Sequential, Model, load_model
from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D, Conv2D, MaxPooling2D

os.environ['CUDA_VISIBLE_DEVICES'] = '7'

imagedir = "BIG-15"

epoch = 300
save_parameters = 'results/VGG16-transfer.h5'



def preprocess_input(x):
    x /= 255.
    x -= 0.5
    x *= 2.
    return x

cur_dir = os.getcwd()
os.chdir(imagedir)  # the parent folder with sub-folders

# Get number of samples per family
list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names
no_imgs = []  # No. of samples per family
for i in range(len(list_fams)):
    os.chdir(list_fams[i])
    len1 = len(glob.glob('*.png'))
    no_imgs.append(len1)
    os.chdir('..')
num_samples = np.sum(no_imgs)  # total number of all samples

# Compute the labels
y = np.zeros(num_samples)
pos = 0
label = 0
for i in no_imgs:
    print ("Label:%2d\tFamily: %15s\tNumber of images: %d" % (label, list_fams[label], i))
    for j in range(i):
        y[pos] = label
        pos += 1
    label += 1
num_classes = label


# Compute the features
width, height,channels = (224, 224, 3)
X = np.zeros((num_samples, width, height, channels))
cnt = 0
list_paths = [] # List of image paths
print("Processing images ...")
for i in range(len(list_fams)):
    pro = 1
    for img_file in glob.glob(list_fams[i]+'/*.png'):
        list_paths.append(os.path.join(os.getcwd(),img_file))
        img = image.load_img(img_file, target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        X[cnt] = x
        cnt += 1
        pro += 1
print("Images processed: %d" %(cnt))


os.chdir(cur_dir)

# Encoding classes (y) into integers (y_encoded) and then generating one-hot-encoding (Y)
encoder = LabelEncoder()
encoder.fit(y)
y_encoded = encoder.transform(y)
Y = np_utils.to_categorical(y_encoded)

# Creating base_model (VGG16 notop)
image_shape = (224, 224, 3)
base_model = VGG16(weights='imagenet', input_shape=image_shape, include_top=False)

filename = 'extracted-features/BIG15-vgg16features.npy'
if os.path.exists(filename):
    print("Loading VGG16 extracted features from %s ..." %(filename))
    vgg16features = np.load(filename)
else:
    print("Extracting features from VGG16 layers ...")
    vgg16features = base_model.predict(X)
    print("Saving VGG16 extracted features into %s ..." %(filename))
    np.save(filename, vgg16features)

# Create stratified k-fold subsets
kfold = 10  # no. of folds
skf = StratifiedKFold(kfold, shuffle=True,random_state=1)
skfind = [None] * kfold  # skfind[i][0] -> train indices, skfind[i][1] -> test indices
cnt = 0
for index in skf.split(X, y):
    skfind[cnt] = index
    cnt += 1

# Training top_model and saving min training loss weights
num_epochs = epoch
history = []
conf_mat = np.zeros((len(list_fams), len(list_fams)))  # Initializing the Confusion Matrix
early = EarlyStopping(monitor='val_loss', patience=15, mode='min')
checkpointer = ModelCheckpoint(
    filepath=save_parameters,
    monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')

all_time = 0

for i in range(kfold):
    train_indices = skfind[i][0]
    test_indices = skfind[i][1]
    X_train = vgg16features[train_indices]
    Y_train = Y[train_indices]
    X_test = vgg16features[test_indices]
    Y_test = Y[test_indices]
    y_test = y[test_indices]


    top_model = Sequential()
    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))  # input_shape=(7,7,512)
    top_model.add(Dense(4096, activation='relu', name='fc1'))
    top_model.add(Dense(4096, activation='relu', name='fc2'))
    top_model.add(Dense(num_classes, activation='softmax', name='predictions'))
    top_model.compile(optimizer=keras.optimizers.SGD(lr=5e-6, momentum=0.9), loss='categorical_crossentropy',
                      metrics=['accuracy'])


    start = time.time()
    h = top_model.fit(X_train, Y_train, validation_split=1/9, epochs=num_epochs,
                      batch_size=64, verbose=2, callbacks=[early, checkpointer])
    end = time.time()
    history.append(h)

    # load the best top model
    best_model = load_model(save_parameters)

    start_2 = time.time()
    y_prob = best_model.predict(X_test, verbose=2)  # Testing
    y_pred = np.argmax(y_prob, axis=1)
    end_2 = time.time()

    # Print process information
    print("[%d] Test acurracy: %.4f (%.4f s)" % (i, accuracy_score(y_test, y_pred), end - start))
    print()
    print()
    print('-----------------------------------------------------------------------')
    print('the %d fold' % (i + 1))
    print('train a fold using: %.4f s' % (end - start))
    per_fold_time = end - start
    all_time += per_fold_time
    print("predict %d test samples using: %.4f s" % (len(X_test), end_2 - start_2))
    print(classification_report(y_test, y_pred, digits=4))
    print('confusion matrix:')
    print()

    cm = confusion_matrix(y_test, y_pred)  # Compute confusion matrix for this fold
    print(cm)
    conf_mat = conf_mat + cm  # Compute global confusion matrix
    print(conf_mat)


# Computing the average accuracy
avg_acc = np.trace(conf_mat)/sum(no_imgs)
print("Average acurracy: %.4f" %(avg_acc))
print("All time: %.4f" % (all_time))