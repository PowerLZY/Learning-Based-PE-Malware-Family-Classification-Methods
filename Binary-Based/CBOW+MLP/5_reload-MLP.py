# How to load and use weights from a checkpoint
from keras.models import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import keras
import os
import os.path
import glob
import csv

from sklearn.metrics import accuracy_score, classification_report,confusion_matrix

np.random.seed(1)

from keras.preprocessing import image
from keras.preprocessing.image import img_to_array
from keras.applications.imagenet_utils import preprocess_input

from keras.models import Sequential, Model
from keras.models import load_model

from time import sleep

os.environ['CUDA_VISIBLE_DEVICES'] = '2'
test_dir = '/home/mayixuan/bytes-based/ttt/'


filenames = os.listdir(test_dir)
test_num = len(filenames)



# 读入测试集
width, height = (256, 256)
X = np.zeros((test_num, width, height))
cnt = 0
for file in filenames:
    # ------------------------------------
    # x 数组即一个文件的256*256的矩阵
    f = csv.reader(open(test_dir + file, 'r'))
    x = []
    for c in f:
        x.append(c)
    # -------------------------------------
    for m in range(len(x)):
        for n in range(len(x[m])):
            x[m][n] = float(x[m][n])
    # -------------------------------------
    X[cnt] = x
    cnt += 1

print("Test Files processed: %d" %(cnt))
X = X.reshape(X.shape[0], 256*256).astype('float32')   # 将X处理为65536维的输入


# Process lables

y = []

with open('/home/mayixuan/drit-7-dataset/drift-labels.csv', 'r') as f:
    reader = csv.reader(f)
    name = [row[0] for row in reader]   # 文件md5或sha_256
    f.close()

with open('/home/mayixuan/drit-7-dataset/drift-labels.csv', 'r') as f:
    reader = csv.reader(f)
    label = [row[1] for row in reader]  # 标签（要与训练时标签相对应）



for file in filenames:
    first_name = os.path.splitext(os.path.basename(file))[0]
    for i in range(len(name)):
        if first_name == name[i]:
            y.append(int(label[i])-1)

print("Test Files label processed: %d" % (len(y)))


# create model
trained_model = load_model('/home/mayixuan/bytes-based/drift-5-fold-result/fold-5-100-epoch.h5')
trained_model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),
                metrics=['accuracy'])
print("Created model and loaded weights from file")
sleep(6)

# estimate accuracy on test dataset using loaded model
y_prob = trained_model.predict(X, verbose=1)  # Testing
y_pred = np.argmax(y_prob, axis=1)


print(classification_report(y, y_pred, digits=4))
print(confusion_matrix(y, y_pred))

